{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e831913",
   "metadata": {},
   "source": [
    "Firts execute the requirements with \"sudo sh requirements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70683ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hunspell\n",
      "  Using cached hunspell-0.5.5.tar.gz (34 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: hunspell\n",
      "  Building wheel for hunspell (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hunspell: filename=hunspell-0.5.5-cp312-cp312-linux_x86_64.whl size=72804 sha256=8a2f3186e1f23196a8275b9fddd28b39e95783ad37b996d7bd38bbe2627fe0b8\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/a4/1e/1c/3438c8e5af66b88b3bab7d99b7c2ec24a9bfe669b57c3f87a6\n",
      "Successfully built hunspell\n",
      "Installing collected packages: hunspell\n",
      "Successfully installed hunspell-0.5.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install hunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d96c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/jef1056/anime-subtitles/versions/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jef1056/anime-subtitles\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff393a",
   "metadata": {},
   "source": [
    "Change the json files into .txt ones.\n",
    "\n",
    "Execute this code if the files aren't created (they normally already are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f74c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalization(content: str)-> str:\n",
    "    re.match(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffd0339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy because you are not sad and she does not know.\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hunspell\n",
    "\n",
    "# Cargar diccionario en ingl√©s (debe instalarse en el sistema)\n",
    "h = hunspell.HunSpell('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff')\n",
    "\n",
    "def expand_corrections(text):\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if not h.spell(word):  # Si la palabra es incorrecta\n",
    "            suggestions = h.suggest(word)  # Obtener sugerencias\n",
    "            if suggestions:\n",
    "                corrected_words.append(suggestions[0])  # Usa la mejor sugerencia\n",
    "            else:\n",
    "                corrected_words.append(word)  # Mantener la palabra original si no hay sugerencias\n",
    "        else:\n",
    "            corrected_words.append(word)  # Palabra correcta\n",
    "    \n",
    "    return \" \".join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "folder = path + \"/Anime Datasets V4/Preprocessed/Preprocessed\"\n",
    "\n",
    "json_file = [f for f in os.listdir(folder) if f.endswith(\".json\")]\n",
    "file_dictionary = {}\n",
    "\n",
    "for name in json_file:\n",
    "    file_path = os.path.join(folder, name)\n",
    "    new_file = open(\"./animes_subs/\"+ name.replace(\".json\", \".txt\"), \"w\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    content = \"\"    \n",
    "    for line in data.get(\"conversations\", [])[0]:\n",
    "        content += line[0] + \"\\n\"\n",
    "\n",
    "    # CHOOSE YOUR FAVORIT EXPAND CONTRACTIONS AND CORRECTIONS\n",
    "    # new_file.write(content.lower())\n",
    "    # new_file.write(expand_contractions(content).lower())\n",
    "    new_file.write(expand_corrections(content).lower())\n",
    "\n",
    "    new_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
